include "path.conf"

###############
# Arc-Factored Parser for tacl2022
###############

tacl2022_arcfactored = ${path}{
    # Model
    model_name = biaffine
    mlp_arc_dim = 100
    mlp_rel_dim = 100
    dropout_rate = 0.3
    use_edu_head_information = true

    # Training
    adam_eps = 1e-6
    adam_weight_decay = 1e-2
    max_grad_norm = 1.0
}

tacl2022_arcfactored_spanbertbase = ${tacl2022_arcfactored}{
    # Pretrained
    bert_pretrained_name_or_path = ${path.storage}/spanbert_hf_base
    bert_tokenizer_pretrained_name_or_path = bert-base-cased

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 0.0001
    finetune_bert_learning_rate = 2e-6
    finetune_task_learning_rate = 0.00001
}

tacl2022_arcfactored_scibert = ${tacl2022_arcfactored}{
    # Pretrained
    bert_pretrained_name_or_path = allenai/scibert_scivocab_uncased
    bert_tokenizer_pretrained_name_or_path = allenai/scibert_scivocab_uncased

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 0.0001
    finetune_bert_learning_rate = 2e-6
    finetune_task_learning_rate = 0.00001
}

###############
# Shift-Reduce Parser for tacl2022
###############

tacl2022_shiftreduce = ${path}{
    # Model
    model_name = arcstandard
    mlp_dim = 128
    mlp_depth = 1
    dropout_rate = 0.3
    use_edu_head_information = true
    reverse_order = false

    # Training
    adam_eps = 1e-6
    adam_weight_decay = 1e-2
    max_grad_norm = 1.0
}

tacl2022_shiftreduce_spanbertbase = ${tacl2022_shiftreduce}{
    # Pretrained
    bert_pretrained_name_or_path = ${path.storage}/spanbert_hf_base
    bert_tokenizer_pretrained_name_or_path = bert-base-cased

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 0.0001
    finetune_bert_learning_rate = 2e-6
    finetune_task_learning_rate = 0.00001
}

tacl2022_shiftreduce_scibert = ${tacl2022_shiftreduce}{
    # Pretrained
    bert_pretrained_name_or_path = allenai/scibert_scivocab_uncased
    bert_tokenizer_pretrained_name_or_path = allenai/scibert_scivocab_uncased

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 0.0001
    finetune_bert_learning_rate = 2e-6
    finetune_task_learning_rate = 0.00001
}

###############
# Backward Shift-Reduce Parser for tacl2022
###############

tacl2022_backwardsr = ${path}{
    # Model
    model_name = arcstandard
    mlp_dim = 128
    mlp_depth = 1
    dropout_rate = 0.3
    use_edu_head_information = true
    reverse_order = true

    # Training
    adam_eps = 1e-6
    adam_weight_decay = 1e-2
    max_grad_norm = 1.0
}

tacl2022_backwardsr_spanbertbase = ${tacl2022_backwardsr}{
    # Pretrained
    bert_pretrained_name_or_path = ${path.storage}/spanbert_hf_base
    bert_tokenizer_pretrained_name_or_path = bert-base-cased

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 0.0001
    finetune_bert_learning_rate = 2e-6
    finetune_task_learning_rate = 0.00001
}

tacl2022_backwardsr_scibert = ${tacl2022_backwardsr}{
    # Pretrained
    bert_pretrained_name_or_path = allenai/scibert_scivocab_uncased
    bert_tokenizer_pretrained_name_or_path = allenai/scibert_scivocab_uncased

    # Training
    bert_learning_rate = 2e-5
    task_learning_rate = 0.0001
    finetune_bert_learning_rate = 2e-6
    finetune_task_learning_rate = 0.00001
}

###############
# Bootstrapping algorithms
###############

tacl2022_base = ${path}{
    # Bootstrapping (common)
    annotation_reflesh_frequency = 3
    unlabeled_data_sampling_size = 5000
    confidence_measure = predictive_probability # or negative_entropy
    agreement_average = true
    agreement_method = joint # or independent
    selection_method = above # or diff
    topk_ratio = 0.6
    diff_margin = 100

    # Model (common)

    # Training (common)
    max_epoch = 40
    batch_size = 1
    warmup_ratio = 0.1

    # Dataset size (common)
    reduced_unlabeled_dataset_size = -1
    seed_size = 1000
}

# Source-only (A)

so_a = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = so

    # Parser/Model
    parser_types = [arcfactored]
}

# Source-only (S)

so_s = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = so

    # Parser/Model
    parser_types = [shiftreduce]
}

# Source-only (B)

so_b = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = so

    # Parser/Model
    parser_types = [backwardsr]
}

# Self-training (A)

st_a = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = st

    # Parser/Model
    parser_types = [arcfactored]
}

# Self-training (S)

st_s = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = st

    # Parser/Model
    parser_types = [shiftreduce]
}

# Co-training (A, S)

ct_as = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = ct

    # Parser/Model
    parser_types = [arcfactored, shiftreduce]
}

# Co-training (S, B)

ct_sb = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = ct

    # Parser/Model
    parser_types = [shiftreduce, backwardsr]
}

# Tri-training (A, S, B)

tt_asb = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = tt

    # Parser/Model
    parser_types = [arcfactored, shiftreduce, backwardsr]
}

# Asymmetric Tri-training (A, S, B)

at_asb = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = at

    # Parser/Model
    parser_types = [arcfactored, shiftreduce, backwardsr]
}

# Asymmetric Tri-training (S, A, B)

at_sab = ${tacl2022_base}{
    # Bootstrapping
    bootstrapping_type = at

    # Parser/Model
    parser_types = [shiftreduce, arcfactored, backwardsr]
}

###############
# SciDTB x CORD-19 -> COVID19-DTB
###############

# Source-only (A)

so_a_scidtb_cord19_covid19dtb = ${so_a}{
    # Parser/Model
    parser_configs = [tacl2022_arcfactored_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Source-only (S)

so_s_scidtb_cord19_covid19dtb = ${so_s}{
    # Parser/Model
    parser_configs = [tacl2022_shiftreduce_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Source-only (B)

so_b_scidtb_cord19_covid19dtb = ${so_b}{
    # parser/Model
    parser_configs = [tacl2022_backwardsr_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Self-training (A)

st_a_scidtb_cord19_covid19dtb = ${st_a}{
    # Parser/Model
    parser_configs = [tacl2022_arcfactored_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Self-training (S)

st_s_scidtb_cord19_covid19dtb = ${st_s}{
    # Parser/Model
    parser_configs = [tacl2022_shiftreduce_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Co-training (A, S)

ct_as_scidtb_cord19_covid19dtb = ${ct_as}{
    # Parser/Model
    parser_configs = [tacl2022_arcfactored_scibert,
                      tacl2022_shiftreduce_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

ct_as_scidtb_cord19_covid19dtb_above06 = ${ct_as_scidtb_cord19_covid19dtb}{
    # Bootstrapping
    selection_method = above
    topk_ratio = 0.6
}

# Co-training (S, B)

ct_sb_scidtb_cord19_covid19dtb = ${ct_sb}{
    # Parser/Model
    parser_configs = [tacl2022_shiftreduce_scibert,
                      tacl2022_backwardsr_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Tri-training (A, S, B)

tt_asb_scidtb_cord19_covid19dtb = ${tt_asb}{
    # Parser/Model
    parser_configs = [tacl2022_arcfactored_scibert,
                      tacl2022_shiftreduce_scibert,
                      tacl2022_backwardsr_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Asymmetric tri-training (A, S, B)

at_asb_scidtb_cord19_covid19dtb = ${at_asb}{
    # Parser/Model
    parser_configs = [tacl2022_arcfactored_scibert,
                      tacl2022_shiftreduce_scibert,
                      tacl2022_backwardsr_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}

# Asymmetric tri-training (A, S, B)

at_sab_scidtb_cord19_covid19dtb = ${at_sab}{
    # Parser/Model
    parser_configs = [tacl2022_shiftreduce_scibert,
                      tacl2022_arcfactored_scibert,
                      tacl2022_backwardsr_scibert]

    # Datasets
    train_labeled_dataset_name = scidtb
    train_unlabeled_dataset_name = cord19-abst
    test_dataset_name = covid19-dtb
}


